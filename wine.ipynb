{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "572bc359-86fa-418d-9e2b-eae7010ae1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606bbd66-e203-410b-8479-b67b8392ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing dataset: wine\n",
      "\n",
      "\n",
      "Split: 20/80\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "\n",
      "Best Parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Classifier: RandomForest\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.92      0.92        12\n",
      "           2       1.00      0.88      0.93        16\n",
      "           3       0.80      1.00      0.89         8\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.91        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n",
      "\n",
      "Split: 50/50\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        27\n",
      "           2       0.97      0.97      0.97        34\n",
      "           3       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.98        89\n",
      "   macro avg       0.98      0.98      0.98        89\n",
      "weighted avg       0.98      0.98      0.98        89\n",
      "\n",
      "\n",
      "Classifier: RandomForest\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.96      0.98        27\n",
      "           2       0.97      1.00      0.99        34\n",
      "           3       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.99        89\n",
      "   macro avg       0.99      0.99      0.99        89\n",
      "weighted avg       0.99      0.99      0.99        89\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.96      0.93        27\n",
      "           2       0.94      0.88      0.91        34\n",
      "           3       0.89      0.89      0.89        28\n",
      "\n",
      "    accuracy                           0.91        89\n",
      "   macro avg       0.91      0.91      0.91        89\n",
      "weighted avg       0.91      0.91      0.91        89\n",
      "\n",
      "\n",
      "Split: 80/20\n",
      "\n",
      "\n",
      "Classifier: SVM\n",
      "\n",
      "Best Parameters: {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97        47\n",
      "           2       0.98      0.88      0.93        60\n",
      "           3       0.88      1.00      0.94        36\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.95      0.94       143\n",
      "weighted avg       0.95      0.94      0.94       143\n",
      "\n",
      "\n",
      "Classifier: RandomForest\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97        47\n",
      "           2       0.98      0.90      0.94        60\n",
      "           3       0.88      0.97      0.92        36\n",
      "\n",
      "    accuracy                           0.94       143\n",
      "   macro avg       0.94      0.95      0.94       143\n",
      "weighted avg       0.95      0.94      0.94       143\n",
      "\n",
      "\n",
      "Classifier: DecisionTree\n",
      "\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.91      0.95        47\n",
      "           2       0.90      0.88      0.89        60\n",
      "           3       0.82      0.92      0.87        36\n",
      "\n",
      "    accuracy                           0.90       143\n",
      "   macro avg       0.90      0.90      0.90       143\n",
      "weighted avg       0.91      0.90      0.90       143\n",
      "\n",
      "\n",
      "Average Weighted Accuracy by Partition:\n",
      "\n",
      "20/80: {'SVM': 1.0, 'RandomForest': 1.0, 'DecisionTree': 0.9179012345679012}\n",
      "50/50: {'SVM': 0.9775280898876404, 'RandomForest': 0.9887394653319937, 'DecisionTree': 0.9098934773092076}\n",
      "80/20: {'SVM': 0.9438293763652615, 'RandomForest': 0.9442063657166633, 'DecisionTree': 0.9029798493956627}\n"
     ]
    }
   ],
   "source": [
    "# Load the wine dataset\n",
    "def load_dataset(filepath, columns):\n",
    "    data = pd.read_csv(filepath, header=None)\n",
    "    data.columns = columns\n",
    "    data = shuffle(data, random_state=42)\n",
    "    return data\n",
    "\n",
    "# Define wine dataset path and column names\n",
    "wine_dataset = {\n",
    "    \"path\": \"wine.data\",\n",
    "    \"columns\": [\n",
    "        \"Class\", \"Alcohol\", \"Malic_Acid\", \"Ash\", \"Alcalinity_of_Ash\", \"Magnesium\", \n",
    "        \"Total_Phenols\", \"Flavanoids\", \"Nonflavanoid_Phenols\", \"Proanthocyanins\", \n",
    "        \"Color_Intensity\", \"Hue\", \"OD280/OD315\", \"Proline\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Hyperparameter grid search for each classifier\n",
    "def perform_grid_search(clf, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "# Define classifiers and their parameter grids\n",
    "classifiers = {\n",
    "    \"SVM\": {\n",
    "        \"model\": svm.SVC(),\n",
    "        \"params\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 10, 20]}\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"model\": tree.DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5, 10]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process the wine dataset\n",
    "print(\"\\nProcessing dataset: wine\\n\")\n",
    "data = load_dataset(wine_dataset[\"path\"], wine_dataset[\"columns\"])\n",
    "\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data[\"Class\"]\n",
    "\n",
    "# Normalize features\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "splits = {\n",
    "    \"20/80\": 0.2,\n",
    "    \"50/50\": 0.5,\n",
    "    \"80/20\": 0.8\n",
    "}\n",
    "\n",
    "average_weighted_accuracies = {\"20/80\": {}, \"50/50\": {}, \"80/20\": {}}\n",
    "\n",
    "for split_name, test_size in splits.items():\n",
    "    print(f\"\\nSplit: {split_name}\\n\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    for clf_name, clf_info in classifiers.items():\n",
    "        print(f\"\\nClassifier: {clf_name}\\n\")\n",
    "        best_model, best_params = perform_grid_search(clf_info[\"model\"], clf_info[\"params\"], X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        average_weighted_accuracies[split_name][clf_name] = report[\"weighted avg\"][\"f1-score\"]\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage Weighted Accuracy by Partition:\\n\")\n",
    "for split, accuracies in average_weighted_accuracies.items():\n",
    "    print(f\"{split}: {accuracies}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
